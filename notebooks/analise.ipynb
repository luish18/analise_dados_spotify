{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de dados Spotify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini projeto para a análise do dataset de músicas do spotify descrito a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Explanations**\n",
    "Dataset contains 19.000 songs and has 15 features like duration ms, key, audio mode, acousticness, danceability, energy and so on .\n",
    "\n",
    "**duration_ms**: The duration of the track in milliseconds.\n",
    "\n",
    "**key**: The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation . E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on. If no key was detected, the value is -1.\n",
    "\n",
    "**audio_mode**: Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.\n",
    "\n",
    "**time_signature**: An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).\n",
    "\n",
    "**acousticness**: A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.\n",
    "\n",
    "**danceability**: Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.\n",
    "\n",
    "**energy**: Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale.\n",
    "\n",
    "**instrumentalness**: \tPredicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.\n",
    "\n",
    "**loudness**: The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db.\n",
    "\n",
    "**speechiness**: Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music.Values below 0.33 most likely represent music and other non-speech-like tracks.\n",
    "\n",
    "**audio_valence**: A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n",
    "**tempo**: The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.\n",
    "\n",
    "**song_popularity**: Song ratings of spotify audience.\n",
    "\n",
    "**liveness**: Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas e dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spotify.csv', index_col=0)\n",
    "df.set_index('song_name', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise inicial do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apesar de as features serem apresentadas como sendo de natureza numérica, percebemos que quase todas são definidas como strings(`object`) com exceção de *audio_valence* e *key*. Também notamos como algumas features apresentam unidades erradas(*acousticness* e *danceability*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisamos transformar os dados do tipo `object` em dados numéricos ou categóricos de acordo com sua funcionalidade. Para isso, precisamos eliminar os dados faltantes que, examinando o dataset, estão representados como `nao_sei`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de mudarmos os dados para numéricos, precisamos garantir que estão todos limpos de caracteres que não representem números."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['song_popularity'].replace('nao_sei', None, inplace=True)\n",
    "df['song_popularity'] = df['song_popularity'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['song_duration_ms'].replace('nao_sei', None, inplace=True)\n",
    "df['song_duration_ms'] = df['song_duration_ms'].str.strip('kg')\n",
    "df['song_duration_ms'] = df['song_duration_ms'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['acousticness'].replace('nao_sei', None, inplace=True)\n",
    "df['acousticness'] = df['acousticness'].str.strip('kgmol/L')\n",
    "df['acousticness'] = df['acousticness'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['danceability'].replace('nao_sei', None, inplace=True)\n",
    "df['danceability'] = df['danceability'].str.strip('kgmol/L')\n",
    "df['danceability'] = df['danceability'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['energy'].replace('nao_sei', None, inplace=True)\n",
    "df['energy'] = df['energy'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['instrumentalness'].replace('nao_sei', None, inplace=True)\n",
    "df['instrumentalness'] = df['instrumentalness'].str.strip('kgmol/L')\n",
    "df['instrumentalness'] = df['instrumentalness'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['liveness'].replace('nao_sei', None, inplace=True)\n",
    "df['liveness'] = df['liveness'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['loudness'].replace('nao_sei', None, inplace=True)\n",
    "df['loudness'] = df['loudness'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['audio_mode'].replace('nao_sei', None, inplace=True)\n",
    "df.dropna()\n",
    "df['audio_mode'] = df['audio_mode'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['speechiness'].replace('nao_sei', None, inplace=True)\n",
    "df['speechiness'] = df['speechiness'].str.strip('nao_sei')\n",
    "df['speechiness'] = df['speechiness'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tempo'].replace('nao_sei', None, inplace=True)\n",
    "df['tempo'] = df['tempo'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_signature'].replace('nao_sei', None, inplace=True)\n",
    "df['time_signature'] = df['time_signature'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['key'].replace('nao_sei', None, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de dados categóricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`audio_mode` descreve a escala de que se deriva a melodia da música. Sendo que 1 representa *major* e 0 *minor*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.audio_mode.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['audio_mode'].replace('0', 'minor', inplace=True) #substitui 0 por 'minor'\n",
    "df['audio_mode'].replace('1', 'major', inplace=True) #substitui 1 por 'major'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.catplot('audio_mode', data=df, kind='count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos como a maioria das músicas no dataset estão na escala *major*. A teoria nos diz que, em geral, músicas nessa escala soam mais 'felizes' e músicas em escala 'minor' soam mais 'tristes'. No nosso dataset, a feature que define essa característica é `audio_valence`, por meio dela podemos averiguar a validade da teoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.catplot('audio_valence', 'audio_mode', data=df, kind='boxen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apesar do que a teoria nos diz, a escala da música não parece afetar de forma significativa sua valência. O que o gráfico acima nos mostra é que há uma distribuição bem uniforme da valência das entradas quanto a sua escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "minor = df[df['audio_mode'] == 'minor']\n",
    "major = df[df['audio_mode'] == 'major']\n",
    "\n",
    "sns.distplot(minor['song_popularity'], hist=False, label='minor')\n",
    "sns.distplot(major['song_popularity'], hist=False, label='major')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também percebemos que não parece haver uma clara preferência do público quanto a escala de uma música. Tanto a escala maior quanto a menor aparentam ser igualmente populares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de dados numéricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para analisarmos os dados numéricos, começamos com o comportamento geral das features e uma visualização da correlação entre os dados. Dessa forma temos um norte melhor para onde devemos concentrar nossa análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da tabela percebemos um comportamento fora do descrito para a feature `song_duration_ms`. Essa feature, demonstrando o tempo de duração das músicas em ms, deveria ter somente valores positivos. No entanto, parecem ocorrer valores negativos que vamos desconsideraremo para a nossa análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duracao_negativa = df[df['song_duration_ms'] < 0]\n",
    "\n",
    "duracao_negativa['song_duration_ms'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.distplot(df['song_duration_ms'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nossa suspeita é confirmada pela visualização acima. Os valores válidos maiores que 0 em um pico e outro abaixo de 0 a ser desconsiderado. Escolhemos desconsiderar os valores negativos uma vez que, pela descrição, percebemos que são poucos os dados que saem do padrão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retirando durações negativas do dataset\n",
    "df = df[df['song_duration_ms'] >= 0]\n",
    "\n",
    "df.song_duration_ms.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.distplot(df.song_duration_ms)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_song_duration = df[df['song_duration_ms'] >= 600000]\n",
    "\n",
    "outliers_song_duration['song_duration_ms'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também percebemos uma pequena discrepância na feature `loudness`. Seus valores deveriam variar entre -60dB e 0dB, no entanto, observamos valores maiores que zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['loudness'] <= 0]\n",
    "df.loudness.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mesmo com todos os dados em um intervalo regular, ainda temos dificuldade de visualizar a distribuição devido à presença de outliers. Por isso, para a análise consideraremos apenas as músicas com duração menor que 600000ms(10min). Essa escolha não deve ter grande efeito na análise uma vez que existem poucas entradas que apresentam duração maior que 10min(22 músicas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,7))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='YlGnBu_r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do heatmap percebemos que a maioria das features são muito fracamente relacionadas. Porém, algumas apresentam fortes correlações. Começaremos nossa análise numérica por essas features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acousticness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A feature `acousticness` tem forte correlação negativa com `energy` e `loudness`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='acousticness', y='energy',data=df, kind='reg', xlim=(0, 1), ylim=(0,1), scatter_kws={\"s\": 2, 'color': '#eb6b34','alpha':0.5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.acousticness.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.energy.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do gráfico percebemos algumas coisas. Músicas muito caracteristicamente acústicas tendem a ser avaliadas como de baixa 'energia', pouco ativas ou 'calmas'. Porém, também percebemos que a média de acousticness do nosso dataset é relativamente baixa, ou seja, a maioria das músicas não são consideradas acústicas. Já a distribuição de `energy` é mais homegenea com média mais alta, nos mostrando que há uma maior quantidade de músicas 'agitadas' do que 'calmas'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='acousticness', y='loudness',data=df, kind='reg', xlim=(0, 1), ylim=(-60,0), scatter_kws={\"s\": 2, 'color': '#eb6b34','alpha':0.5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loudness.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da mesma forma, há uma correlação negativa de `acousticness` com `loudness`, mesmo que menos intensa em relação à `energy`. No entanto, observamos uma concentração maior na distribuição de `loudness` tendendo a valores mais próximos de 0, ou seja, músicas consideradas menos 'altas'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Danceability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já `danceability` possue relação significativa com `speechiness` e `audio_valence`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='speechiness', y='danceability',data=df, kind='reg', xlim=(0, 1), ylim=(0,1), scatter_kws={\"s\": 2, 'color': '#eb6b34','alpha':0.5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.danceability.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.speechiness.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`speechiness` é a feature que define qual a probabilidade de uma música apresentar discurso falado (em oposição a discurso cantado).\n",
    "Com isso em mente, podemos observar que as músicas estão extremamente concentradas em uma região de baixa `speechiness` isso significa que a maior parte do nosso dataset representa faixas que possuem pouco ou nenhum discurso falado.\n",
    "\n",
    "Também percebemos como a `danceability` parece aumentar com a `speechiness`. Intuitivamente, essa tendêcia vai contra o senso comum. Discursos, podcasts e leituras de poesia não são normalmente consideradas como 'dançaveis'. No entando, analisando a forma como `danceability` é calculdada no dataset, se percebe uma relação clara com rítimo na forma do tempo, regularidade e estabilidade do próprio ritmo. \n",
    "\n",
    "Essa relação inesperada pode ser causa do baixo número de entradas com alta `speechiness` ou a forma como `danceability` é calculada uma vez que, já foi estudada a maior correlação de movimento com música do que com discurso falado (ver [Why Movement Is Captured by Music, but Less by Speech: Role of Temporal Regularity](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0071945))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='audio_valence', y='danceability',data=df, kind='reg', xlim=(0, 1), ylim=(0,1), scatter_kws={\"s\": 2, 'color': '#eb6b34','alpha':0.5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.audio_valence.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como é de se esperar, o quanto uma música é apropriada para dançar aumenta com o quão 'feliz' ela é, como medido pela `audio_valence`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já vimos a relação de `energy` com `acousticness`, mas tambem percebemos forte correlação de `energy` com `loudness` e `audio_valence`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='audio_valence', y='energy',data=df, kind='reg', xlim=(0, 1), ylim=(0,1), scatter_kws={\"s\": 2, 'color': '#eb6b34','alpha':0.5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='loudness', y='energy',data=df, kind='reg',ylim=(0,1),xlim=(-40,0), scatter_kws={\"s\": 2, 'color': '#eb6b34','alpha':0.5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nos gráficos percebemos que tanto `audio_valence` quanto `loudness` têm grande contribuição no quão energética é uma música.`loudness` em especial parece ter maior influencia, nos mostrando que músicas mais barulhentas tendem a ser bem mais energéticas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusões finais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dadas as features apresentadas pelo dataset, percebemos que a grande maioria delas não parecem ser relacionadas. Porém, das poucas que são, observamos uma tendência já prevista pelo senso comum de músicas mais animadas(alta `energy`) e felizes(alta `energy`) serem também mais barulhentas, adequadas para dançar, e ,em geral ,menos calmas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
